{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_means(dataset1, dataset2, alpha):\n",
    "    m,n = len(dataset1), len(dataset2)\n",
    "    \n",
    "    v1, v2 = dataset1.var(), dataset2.var()\n",
    "    se = np.sqrt(v1/len(x1) + v2/len(x2))\n",
    "    \n",
    "    delta = dataset1.mean() - dataset2.mean()\n",
    "    wald = delta/se\n",
    "    \n",
    "    absW = np.abs(wald)\n",
    "    test = -stats.norm.ppf(alpha/2)\n",
    "    \n",
    "    result = {'Wald':wald,'Abs Wald':absW,'z_alpha/2':test, \\\n",
    "              'reject H0':absW > test, 'p-value':2*stats.norm.cdf(-absW)}\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Wald': -0.16606886648720393,\n",
       " 'Abs Wald': 0.16606886648720393,\n",
       " 'z_alpha/2': 2.575829303548901,\n",
       " 'reject H0': False,\n",
       " 'p-value': 0.8681027548503396}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.random.uniform(0,1,10000)\n",
    "x2 = np.random.uniform(0,1,100)\n",
    "alpha = 0.01\n",
    "compare_means(x1,x2,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_compare_models_diff_test(model1, model2, error_threshold, test_sample1, \\\n",
    "                                               test_sample2, alpha = 0.01):\n",
    "    \"\"\"\n",
    "    test_samplei = (X,y) tuple\n",
    "    models need a predict function\n",
    "    \"\"\"\n",
    "    m = len(test_sample1[0])\n",
    "    n = len(test_sample2[0])\n",
    "    \n",
    "    error_test_1 = model1.predict(test_sample1[0]) - test_sample1[1]\n",
    "    error_test_2 = model2.predict(test_sample2[0]) - test_sample2[1]\n",
    "    \n",
    "    errors1_bool = np.array(abs(error_test_1) < error_threshold, dtype = int)\n",
    "    errors2_bool = np.array(abs(error_test_2) < error_threshold, dtype = int)\n",
    "    \n",
    "    #model the errors as binomials coeffecients.\n",
    "    #MLE for p in binomial distribution is success/total_attempts\n",
    "    \n",
    "    p1 = errors1_bool.mean()\n",
    "    p2 = errors2_bool.mean()\n",
    "\n",
    "    delta = p1 - p2\n",
    "    se = np.sqrt((p1*(1-p1))/m + (p2*(1-p2))/n)\n",
    "\n",
    "    wald = delta/se\n",
    "\n",
    "    absW = np.abs(wald)\n",
    "    test = -stats.norm.ppf(alpha/2)\n",
    "\n",
    "    result = {'Wald':wald,'Abs Wald':absW,'z_alpha/2':test, \\\n",
    "                  'reject H0':absW > test, 'p-value':2*stats.norm.cdf(-absW)}\n",
    "    \n",
    "    return result\n",
    "\n",
    "def linear_regression_compare_models_same_test(model1, model2, error_threshold, test_sample, alpha = 0.01):\n",
    "    \"\"\"\n",
    "    test_samplei = (X,y) tuple\n",
    "    models need a predict function\n",
    "    \"\"\"\n",
    "    m = len(test_sample[0])\n",
    "    \n",
    "    error_test_1 = model1.predict(test_sample[0]) - test_sample[1]\n",
    "    error_test_2 = model2.predict(test_sample[0]) - test_sample[1]\n",
    "    \n",
    "    errors1_bool = np.array(abs(error_test_1) < error_threshold, dtype = int)\n",
    "    errors2_bool = np.array(abs(error_test_2) < error_threshold, dtype = int)\n",
    "    \n",
    "    D = errors1_bool - errors2_bool\n",
    "    n = len(D)\n",
    "    delta = D.mean()\n",
    "    se = np.sqrt(sum((D-delta)**2)/n)/np.sqrt(n)\n",
    "    wald = delta/se\n",
    "\n",
    "    absW = np.abs(wald)\n",
    "    test = -stats.norm.ppf(alpha/2)\n",
    "\n",
    "    result = {'Wald':wald,'Abs Wald':absW,'z_alpha/2':test, \\\n",
    "                      'reject H0':absW > test, 'p-value':2*stats.norm.cdf(-absW)}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the result of two algorithms\n",
    "\n",
    "from sklearn import linear_model\n",
    "X = np.random.uniform(0,1,(2000,3))\n",
    "alpha = 32.12\n",
    "beta = np.array([2.3,4.3,44])\n",
    "Y = np.matmul(beta,X.T) + alpha + np.random.normal(0,1,len(X))\n",
    "\n",
    "\n",
    "training = X[:1000], Y[:1000]\n",
    "test_sample1 = X[1000:1500], Y[1000:1500]\n",
    "test_sample2 = X[1500:], Y[1500:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Wald': 1.3737222812363337,\n",
       " 'Abs Wald': 1.3737222812363337,\n",
       " 'z_alpha/2': 2.575829303548901,\n",
       " 'reject H0': False,\n",
       " 'p-value': 0.169527916926962}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(training[0], training[1])\n",
    "\n",
    "linear_regression_compare_models_diff_test(lr,lr, 1, test_sample1, test_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Wald': -0.5693944925419576,\n",
       " 'Abs Wald': 0.5693944925419576,\n",
       " 'z_alpha/2': 2.575829303548901,\n",
       " 'reject H0': False,\n",
       " 'p-value': 0.5690884535490858}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(training[0],training[1])\n",
    "\n",
    "linear_regression_compare_models_diff_test(tree,tree, 1, test_sample1, test_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Wald': 7.100244404181735,\n",
       " 'Abs Wald': 7.100244404181735,\n",
       " 'z_alpha/2': 2.575829303548901,\n",
       " 'reject H0': True,\n",
       " 'p-value': 1.245364547909418e-12}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_compare_models_diff_test(lr,tree, 1, test_sample1, test_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Wald': 8.868460060230055,\n",
       " 'Abs Wald': 8.868460060230055,\n",
       " 'z_alpha/2': 2.575829303548901,\n",
       " 'reject H0': True,\n",
       " 'p-value': 7.416435654464869e-19}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_compare_models_same_test(lr,tree, 1, test_sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import chi2\n",
    "\n",
    "\n",
    "def pearsonChi2Statistic(p0, data, alpha = 0.05):\n",
    "    \"\"\"\n",
    "    H0 : the data comes from p0\n",
    "    eg.\n",
    "    p0 = {1:0.2,2:0.2,3:0.2,4:0.4}\n",
    "    data = np.random.choice(list(p0.keys()),p = list(p0.values()), size= 100)\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    categories = np.unique(data)\n",
    "    k = len(categories)\n",
    "    \n",
    "    counter = {}\n",
    "    for x in data:\n",
    "        if x in counter.keys():\n",
    "            counter[x]+=1\n",
    "        else:\n",
    "            counter[x] = 1\n",
    "    T = 0\n",
    "    for q in p0.keys():\n",
    "        if q in counter.keys():\n",
    "            count = counter[q]\n",
    "        else:\n",
    "            count = 0\n",
    "        diff = count - p0[q]*n\n",
    "        num = diff*diff\n",
    "        den = p0[q]*n\n",
    "        T+=num/den\n",
    "        \n",
    "    p_value =  1 - chi2.cdf(T, df = k-1)\n",
    "    if p_value < alpha:\n",
    "        reject = True\n",
    "    else:\n",
    "        reject = False\n",
    "    \n",
    "    return {'T' : T, 'p-value' :p_value, 'reject H0':reject}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T': 2.69, 'p-value': 0.44192936543217587, 'reject H0': False}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = {1:0.2,2:0.2,3:0.2,4:0.4}\n",
    "data = np.random.choice(list(p0.keys()),p = list(p0.values()), size= 1000)\n",
    "pearsonChi2Statistic(p0,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T': 95.71000000000001, 'p-value': 0.0, 'reject H0': True}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = {1:0.2,2:0.2,3:0.2,4:0.4}\n",
    "data = np.random.choice([1,2,3,4],p = [0.25,0.25,0.25,0.25], size= 1000)\n",
    "pearsonChi2Statistic(p0,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_counter(array):\n",
    "    d = {}\n",
    "    for x in array:\n",
    "        if x not in d.keys():\n",
    "            d[x] = 1\n",
    "        else:\n",
    "            d[x]+=1\n",
    "    return d\n",
    "\n",
    "def create_probabilities(array):\n",
    "    n = len(array)\n",
    "    res = create_counter(array)\n",
    "    new_res = {}\n",
    "    for k,v in res.items():\n",
    "        new_res[k] = v/n\n",
    "    return new_res, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pearsonchi2 to evaluation association between two categorial datasets.\n",
    "\n",
    "\n",
    "#null hypothesis is that the probability for these to occur is independent, so\n",
    "# P([A,C]) = P(A)*P(C) where P(A) would just be the MLE of the bernoulli distribution\n",
    "# i.e count(A)/n. Let's do that:\n",
    "def chi2_test_for_categorical_data(data,alpha = 0.05):\n",
    "    col1, col2 = list(zip(*data))\n",
    "    n1, n2 = len(col1), len(col2)\n",
    "    N = len(data)\n",
    "    p1, c1 = create_probabilities(col1)\n",
    "    p2, c2 = create_probabilities(col2)\n",
    "\n",
    "    c1_unique = np.unique(col1)\n",
    "    c2_unique = np.unique(col2)\n",
    "\n",
    "    l1 = len(c1_unique)\n",
    "    l2 = len(c2_unique)\n",
    "\n",
    "    probs = {}\n",
    "    for i1 in c1_unique:\n",
    "        for i2 in c2_unique:\n",
    "            probs[tuple((i1,i2))] = p1[i1]*p2[i2]\n",
    "\n",
    "    expectation = {}\n",
    "    for k,v in probs.items():\n",
    "        expectation[k] = probs[k]*N\n",
    "\n",
    "    counter = {}\n",
    "    for x in data:\n",
    "        if tuple(x) not in counter.keys():\n",
    "            counter[tuple(x)] = 1\n",
    "        else:\n",
    "            counter[tuple(x)]+=1\n",
    "\n",
    "    for k in expectation.keys():\n",
    "        if k not in counter.keys():\n",
    "            counter[k] = 0\n",
    "\n",
    "    T = 0\n",
    "    for k in counter.keys():\n",
    "        diff = counter[k] - expectation[k]\n",
    "        num = diff*diff\n",
    "        den = expectation[k]\n",
    "        T+=num/den\n",
    "\n",
    "    p_value =  1 - chi2.cdf(T, df = (l1-1)*(l2-1))\n",
    "    \n",
    "    if p_value  <alpha:\n",
    "        reject = True\n",
    "    else:\n",
    "        reject = False\n",
    "    \n",
    "    return {'T' : T, 'p-value' :p_value, 'reject H0':reject}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T': 2.2222222222222223, 'p-value': 0.13603712811414426, 'reject H0': False}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [['A','C'],['B','D'],['A','C'],['A','D'],['B','D']]\n",
    "chi2_test_for_categorical_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T': 11.942092624356775, 'p-value': 0.01778711460986071, 'reject H0': True}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [['A1','B1']]*11 + [['A2','B1']]*3 + [['A3','B1']]*8 + [['A1','B2']]*2 + [['A2','B2']]*9 + [['A3','B2']]*14\\\n",
    "+[['A1','B3']]*12 + [['A2','B3']]*13 + [['A3','B3']]*28\n",
    "chi2_test_for_categorical_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation testing\n",
    "\n",
    "# H_0 the two samples come from the same distributions...use a simple metric as T, e.g. X_bar, Y_bar \n",
    "#or something like that\n",
    "\n",
    "#define the metric outside of the main hypothesis function:\n",
    "\n",
    "\n",
    "\n",
    "#datasets\n",
    "\n",
    "\n",
    "def permutation_test(T_function, dataset1, dataset2, batch ,alpha = 0.05):\n",
    "    \"\"\"\n",
    "    H0 : datasets are coming form the same distribution.\n",
    "    \"\"\"\n",
    "    n = len(dataset1)\n",
    "    t_obs = abs(mean(dataset1) - mean(dataset2))\n",
    "    joined = np.concatenate([dataset1,dataset2])\n",
    "\n",
    "    Ts = []\n",
    "    T_larger_than_t_obs = []\n",
    "\n",
    "    for _ in range(B):\n",
    "\n",
    "        shuffled = np.random.permutation(joined)\n",
    "        s1, s2 = shuffled[:n1], shuffled[n1:]\n",
    "        T = abs(mean(s1) - mean(s2))\n",
    "        Ts.append(T)\n",
    "        \n",
    "    p_value = np.array(np.array(Ts) > t_obs,int).mean()\n",
    "    \n",
    "    if p_value < alpha:\n",
    "        reject = True\n",
    "    else:\n",
    "        reject = False\n",
    "    return {'p_value':p_value,'reject H0':reject}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_value': 0.0, 'reject H0': True}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean(sample_array):\n",
    "    return np.array(sample_array).mean()\n",
    "\n",
    "set1 = np.random.normal(2,3,10000)\n",
    "set2 = np.random.normal(2,3,10000)\n",
    "set3 = np.random.uniform(2,3,10000)\n",
    "\n",
    "n1 = len(set1)\n",
    "n2 = len(set2)\n",
    "n3 = len(set3)\n",
    "\n",
    "permutation_test(mean, set1, set3, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('ml_env': conda)",
   "language": "python",
   "name": "python36964bitmlenvconda9f54039d931e4029adcffd4ea832f0f0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
