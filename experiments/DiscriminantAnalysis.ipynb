{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# least square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminantModel:\n",
    "    pass\n",
    "\n",
    "class LeastSquares(DiscriminantModel):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def setUp(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.K = len(self.classes)\n",
    "        \n",
    "        \n",
    "        idx = 0\n",
    "        self.N,self.p = X.shape\n",
    "        new_col = np.array([1]*self.N)\n",
    "        self.X = np.insert(X, idx, new_col, axis=1)\n",
    "        \n",
    "        self.T = np.zeros((self.K,len(y)))\n",
    "        for i,c in enumerate(self.classes):\n",
    "            self.T[i] = np.array(Y == self.classes[i],int)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.setUp(X,y)\n",
    "        \n",
    "        first = inv(np.matmul(self.X.T,self.X))\n",
    "        second = np.matmul(self.X.T, self.T.T)\n",
    "        self.W = np.matmul(first, second).T\n",
    "        \n",
    "    def loss(self):\n",
    "        diff = np.matmul(self.W,self.X.T) - T\n",
    "        E = np.trace(np.matmul(diff, diff.T))/2\n",
    "        return E\n",
    "    \n",
    "    \n",
    "    def predict_discriminant_function(self, X):\n",
    "        \n",
    "        n_w, p_w  = self.W.shape\n",
    "        n_x, p_x = X.shape\n",
    "        if p_x != p_w:\n",
    "            idx = 0\n",
    "            new_col = np.array([1]*n_x)\n",
    "            X = np.insert(X, idx, new_col, axis=1)\n",
    "        return np.matmul(self.W,X.T).T\n",
    "        \n",
    "    def predict(self,X):\n",
    "\n",
    "        disc = self.predict_discriminant_function(X)\n",
    "        return np.argmax(disc,1)\n",
    "    \n",
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    Binary case\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def setUp(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.K = len(self.classes)\n",
    "        \n",
    "        self.y = y\n",
    "        idx = 0\n",
    "        self.N,self.p = X.shape\n",
    "        new_col = np.array([1]*self.N)\n",
    "        self.X = np.insert(X, idx, new_col, axis=1)\n",
    "        self.T = self.y - np.array(self.y == 0,int)\n",
    "        \n",
    "        self.W = self.X.mean(0)\n",
    "        \n",
    "    def _find_misclassifications(self):\n",
    "        res = np.array(np.matmul(self.W,self.X.T) >= 0,int) - np.array(np.matmul(self.W,self.X.T) < 0,int)\n",
    "        misclassified_indices = np.where(res != self.T) \n",
    "        return misclassified_indices\n",
    "        \n",
    "    def loss(self):\n",
    "        misclassified_indices = self._find_misclassifications()\n",
    "        X_part = np.matmul(self.W,self.X[misclassified_indices].T)\n",
    "        T_part = self.T[misclassified_indices]\n",
    "\n",
    "        return -np.sum(np.multiply(X_part, T_part))\n",
    "    \n",
    "    def fit(self, X, y, learning_rate = 0.001, max_iterations = 10000, print_every = 1000, tolerance = 10e-8,\\\n",
    "           verbose = True):\n",
    "        self.setUp(X,y)\n",
    "        current_W = self.W\n",
    "        for _ in range(max_iterations):\n",
    "\n",
    "            misclassified_indices = self._find_misclassifications()\n",
    "            X_part = self.X[misclassified_indices]\n",
    "            T_part = self.T[misclassified_indices]\n",
    "            self.W = self.W + learning_rate*np.matmul(X_part.T, T_part)\n",
    "            loss = self.loss()\n",
    "            if _%print_every==0:\n",
    "                if verbose:\n",
    "                    print(loss)\n",
    "            if abs(np.sum(self.W - current_W)) < tolerance:\n",
    "                if verbose:\n",
    "                    print('Tolerance reached at {} with inner product difference {}'.\\\n",
    "                          format(self.W, abs(np.sum(self.W - current_W))))\n",
    "                break\n",
    "            \n",
    "            if loss == 0:\n",
    "                if verbose:\n",
    "                    print('Loss = 0 reached')\n",
    "                break\n",
    "                \n",
    "    def predict_discriminant(self, X):\n",
    "        n_w  = self.W.shape\n",
    "        n_x, p_x = X.shape\n",
    "        if p_x != n_w:\n",
    "            idx = 0\n",
    "            new_col = np.array([1]*n_x)\n",
    "            X = np.insert(X, idx, new_col, axis=1)\n",
    "        return np.matmul(self.W,X.T)    \n",
    "\n",
    "        \n",
    "    def predict(self,X):\n",
    "        disc = self.predict_discriminant(X)\n",
    "        return np.array(disc > 0,int)\n",
    "    \n",
    "    \n",
    "class DiscriminantAnalysis:\n",
    "    def __init__(self, alpha = 1):\n",
    "        # alpha = 1 : full QDA\n",
    "        # alpha = 0 : LDA (pooled covariance matrices)\n",
    "        self.alpha = alpha\n",
    "        #alpha preset to one so that we have quadratic discriminant\n",
    "            \n",
    "    def setUp(self, X, y):\n",
    "        self.y = y\n",
    "        self.X = X\n",
    "        self.classes = np.unique(self.y)\n",
    "        \n",
    "        if (np.sort(self.classes) != np.arange(len(self.classes))).all():\n",
    "            raise ValueError('Please make class labels increasing integers')\n",
    "        \n",
    "        self.K = len(self.classes)\n",
    "        self.n, self.p = self.X.shape\n",
    "        \n",
    "    def _compute_k_data(self):\n",
    "        self.prior = {}\n",
    "        self.means = {}\n",
    "        self.covariances = {}\n",
    "        self.Nk = {}\n",
    "\n",
    "        for k in self.classes:\n",
    "            idx = np.where(Y == k)\n",
    "            X_temp = X[idx]\n",
    "            self.Nk[k] = X_temp.shape[0]\n",
    "            self.prior[k] = self.Nk[k]/self.n\n",
    "            self.means[k] = X_temp.mean(0)\n",
    "            self.covariances[k] = np.cov(X_temp.T)\n",
    "            \n",
    "    def _compute_pooled_covariance(self):\n",
    "        self.pooled_covariance = 0\n",
    "        for k,v in self.covariances.items():\n",
    "            self.pooled_covariance+=v*self.n*self.prior[k]\n",
    "        self.pooled_covariance*=(1/(self.n-self.K))\n",
    "        \n",
    "    def _compute_reg_covariance(self):\n",
    "        for k in self.covariances.keys():\n",
    "            self.covariances[k] = self.alpha*self.covariances[k] +  (1-self.alpha)*self.pooled_covariance\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.setUp(X,y)\n",
    "        self._compute_k_data()\n",
    "        self._compute_pooled_covariance()\n",
    "        self._compute_reg_covariance()\n",
    "        \n",
    "    def _delta(self,k,x):\n",
    "        first = 0.5*np.log(np.linalg.det(self.covariances[k]))\n",
    "        diff = (x - self.means[k])\n",
    "        second = 0.5*np.sum(diff*np.matmul(diff, np.linalg.inv(self.covariances[k])),1)\n",
    "        third = np.log(self.prior[k])\n",
    "\n",
    "        return -first - second + third\n",
    "        \n",
    "    def predict_discriminant(self, X):\n",
    "        n,p = X.shape\n",
    "        delta = np.zeros((n,self.K))\n",
    "        \n",
    "        for k in self.classes:\n",
    "            delta[:,k] = self._delta(k,X)\n",
    "        \n",
    "        return delta\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_discriminant(X),1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data with many classes:\n",
    "def generate_data(classes, method = 'hard'):\n",
    "    X = np.random.uniform(-1,1,(1000,2))\n",
    "\n",
    "    # random function\n",
    "    if method == 'hard':\n",
    "        Y = np.sin(X)**2 + np.tanh(X)\n",
    "    else:\n",
    "        Y = X\n",
    "    Y = np.sum(Y,1)\n",
    "    K = np.arange(classes)\n",
    "    \n",
    "\n",
    "\n",
    "    boundaries = [np.quantile(Y,i/classes) for i in range(1,classes)]\n",
    "    boundaries = [np.min(Y)] + boundaries + [np.max(Y) + 10-5]\n",
    "    Y_class = []\n",
    "    for y in Y:\n",
    "        for i in range(0,len(boundaries)-1):\n",
    "            if (boundaries[i] <= y) and (y < boundaries[i+1]):\n",
    "                Y_class.append(i)\n",
    "                break\n",
    "    Y = np.array(Y_class)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = generate_data(2, 'easy')\n",
    "\n",
    "model = LeastSquares()\n",
    "model.fit(X,Y)\n",
    "np.sum(model.predict(X) == Y)/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.643"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = generate_data(3, 'hard')\n",
    "\n",
    "model = LeastSquares()\n",
    "model.fit(X,Y)\n",
    "np.sum(model.predict(X) == Y)/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron (only for the binary case)\n",
    "\n",
    "X,Y = generate_data(2, 'easy')\n",
    "model = Perceptron()\n",
    "model.fit(X,Y,verbose = False)\n",
    "np.sum(model.predict(X) == Y)/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.863"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = generate_data(2, 'hard')\n",
    "model = Perceptron()\n",
    "model.fit(X,Y,verbose = False)\n",
    "np.sum(model.predict(X) == Y)/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.994,\n",
       " 0.05263157894736842: 0.993,\n",
       " 0.10526315789473684: 0.993,\n",
       " 0.15789473684210525: 0.992,\n",
       " 0.21052631578947367: 0.992,\n",
       " 0.2631578947368421: 0.992,\n",
       " 0.3157894736842105: 0.992,\n",
       " 0.3684210526315789: 0.992,\n",
       " 0.42105263157894735: 0.992,\n",
       " 0.47368421052631576: 0.992,\n",
       " 0.5263157894736842: 0.992,\n",
       " 0.5789473684210527: 0.992,\n",
       " 0.631578947368421: 0.992,\n",
       " 0.6842105263157894: 0.992,\n",
       " 0.7368421052631579: 0.992,\n",
       " 0.7894736842105263: 0.992,\n",
       " 0.8421052631578947: 0.991,\n",
       " 0.894736842105263: 0.991,\n",
       " 0.9473684210526315: 0.991,\n",
       " 1.0: 0.991}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DA\n",
    "\n",
    "X,Y = generate_data(2, 'easy')\n",
    "\n",
    "alpha_grid = np.linspace(0,1,20)\n",
    "result = {}\n",
    "\n",
    "for alpha in alpha_grid:\n",
    "    model = DiscriminantAnalysis(alpha = alpha)\n",
    "    model.fit(X,Y)\n",
    "    result[alpha] = np.sum(model.predict(X) == Y)/len(Y)\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.741,\n",
       " 0.05263157894736842: 0.748,\n",
       " 0.10526315789473684: 0.75,\n",
       " 0.15789473684210525: 0.751,\n",
       " 0.21052631578947367: 0.755,\n",
       " 0.2631578947368421: 0.757,\n",
       " 0.3157894736842105: 0.759,\n",
       " 0.3684210526315789: 0.76,\n",
       " 0.42105263157894735: 0.76,\n",
       " 0.47368421052631576: 0.764,\n",
       " 0.5263157894736842: 0.764,\n",
       " 0.5789473684210527: 0.766,\n",
       " 0.631578947368421: 0.771,\n",
       " 0.6842105263157894: 0.772,\n",
       " 0.7368421052631579: 0.775,\n",
       " 0.7894736842105263: 0.778,\n",
       " 0.8421052631578947: 0.78,\n",
       " 0.894736842105263: 0.784,\n",
       " 0.9473684210526315: 0.787,\n",
       " 1.0: 0.792}"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = generate_data(3, 'hard')\n",
    "\n",
    "alpha_grid = np.linspace(0,1,20)\n",
    "result = {}\n",
    "\n",
    "for alpha in alpha_grid:\n",
    "    model = DiscriminantAnalysis(alpha = alpha)\n",
    "    model.fit(X,Y)\n",
    "    result[alpha] = np.sum(model.predict(X) == Y)/len(Y)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('ml_env': conda)",
   "language": "python",
   "name": "python36964bitmlenvconda9f54039d931e4029adcffd4ea832f0f0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
