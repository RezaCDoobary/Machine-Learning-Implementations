{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_index, split_value, left_indices, right_indices):\n",
    "        self.feature_index = feature_index\n",
    "        self.split_value = split_value\n",
    "        self.left_indices = left_indices\n",
    "        self.right_indices = right_indices\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'values = ' + str(self.split_value) +', index = '+ str(self.feature_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(array, classes):\n",
    "    psquared = 0\n",
    "    n = len(array)\n",
    "    for x in classes:\n",
    "        p_temp = np.sum(array == x)/n\n",
    "        psquared+=p_temp*p_temp\n",
    "    return 1 - psquared\n",
    "\n",
    "def entropy(array, classes):\n",
    "    ent = 0\n",
    "    n = len(array)\n",
    "    for x in classes:\n",
    "        p_temp = np.sum(array == x)/n\n",
    "        ent+=-p_temp*np.log(p_temp)\n",
    "    return ent\n",
    "\n",
    "def weighted_average(method, array1, array2, classes, p_1, p_2):\n",
    "    if len(array1) == 0:\n",
    "        gini_1 = 0\n",
    "    else:\n",
    "        gini_1 = method(array1, classes)\n",
    "    \n",
    "    if len(array2) == 0:\n",
    "        gini_2 = 0\n",
    "    else:\n",
    "        gini_2 = method(array2, classes)\n",
    "\n",
    "    return p_1*gini_1 + p_2*gini_2\n",
    "\n",
    "def index(method, target_groups, classes):\n",
    "    N = len(target_groups[0])+len(target_groups[1])\n",
    "    p1,p2 = len(target_groups[0])/N, len(target_groups[1])/N\n",
    "    return weighted_average(method, target_groups[0], target_groups[1], classes,p1,p2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new way\n",
    "\n",
    "def generic_split(feature_index, value, Xdataset):\n",
    "    column = Xdataset[:,feature_index]\n",
    "    \n",
    "    _all = set(range(0,len(column)))\n",
    "    left = set(np.where(column < value)[0])\n",
    "    right = _all - left\n",
    "            \n",
    "    return left, right\n",
    "\n",
    "def get_data_from_idx(left, right, X, Y):\n",
    "    assert(isinstance(left,set))\n",
    "    assert(isinstance(right,set))\n",
    "    \n",
    "    ly, ry, lx, rx = Y[list(left)], Y[list(right)], X[list(left)], X[list(right)]\n",
    "    return ly, ry, lx, rx\n",
    "\n",
    "\n",
    "method = entropy\n",
    "def best_split(Xdataset, Ydataset):\n",
    "    N = len(Xdataset)\n",
    "    feature_space = len(Xdataset[0])\n",
    "    g = np.inf\n",
    "    v = None\n",
    "    feature = None\n",
    "    group = []\n",
    "    \n",
    "    for i in range(0,N):\n",
    "        for j in range(0,feature_space):\n",
    "            left,right = generic_split(j,Xdataset[i][j],Xdataset)\n",
    "            ly, ry, lx, rx = get_data_from_idx(left, right, Xdataset, Ydataset)\n",
    "            g_index = index(method, [ly,ry],list(set(Ydataset)))\n",
    "            if g_index < g:\n",
    "                g = g_index\n",
    "                feature = j\n",
    "                value = Xdataset[i][feature]\n",
    "                group = [left,right]#[[lx,ly],[rx,ry]]\n",
    "    result = Node(feature, value, left, right)#Node(feature, value, group)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminate_with_mode(targets):\n",
    "    from scipy import stats\n",
    "    return stats.mode(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_split(X,y, root, max_depth, min_size, depth):\n",
    "    left_Y, right_Y, left_X, right_X = get_data_from_idx(root.left_indices, root.right_indices, X, y)\n",
    "    \n",
    "    \n",
    "    if len(left_Y) == 0 or len(right_Y) == 0:\n",
    "        root.left = root.right = terminate_with_mode(np.concatenate((left_Y,right_Y)))\n",
    "        return\n",
    "\n",
    "    if depth >= max_depth:\n",
    "        root.left = terminate_with_mode(left_Y)\n",
    "        root.right = terminate_with_mode(right_Y)\n",
    "        return \n",
    "\n",
    "    if len(left_Y) <  min_size:\n",
    "        root.left = terminate_with_mode(left_Y)\n",
    "    else:\n",
    "        root.left = best_split(left_X, left_Y)\n",
    "        main_split(X,y, root.left, max_depth, min_size, depth+1)\n",
    "\n",
    "    if len(right_Y) <  min_size:\n",
    "        root.right = terminate_with_mode(right_Y)\n",
    "    else:\n",
    "        root.right = best_split(right_X, right_Y)\n",
    "        main_split(X,y,root.right, max_depth, min_size, depth+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X_train,y_train, max_depth, min_size):\n",
    "    root = best_split( X_train,y_train)\n",
    "    main_split(X_train, y_train,root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "def predict(model, datapoint):\n",
    "    value = model.split_value\n",
    "    index = model.feature_index\n",
    "    while True:\n",
    "        if datapoint[index] <= value:\n",
    "            model = model.left\n",
    "            if isinstance(model,Node):\n",
    "                value = model.split_value\n",
    "                index = model.feature_index\n",
    "            else:\n",
    "                result = model\n",
    "                break\n",
    "        else:\n",
    "            model = model.right\n",
    "            if isinstance(model,Node):\n",
    "                value = model.split_value\n",
    "                index = model.feature_index\n",
    "            else:\n",
    "                result = model\n",
    "                break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('banknotes.txt', header =None)\n",
    "df.columns = ['X_0','X_1','X_2','X_3','Y']\n",
    "X = df[['X_0','X_1','X_2','X_3']].values\n",
    "y = df['Y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:100]\n",
    "y = y[:100]\n",
    "\n",
    "root = build_tree(X,y,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.array([predict(root,x)[0][0] for x in X])\n",
    "np.sum(res == y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('ml_env': conda)",
   "language": "python",
   "name": "python36964bitmlenvconda9f54039d931e4029adcffd4ea832f0f0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
