{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# generate data with many classes:\n",
    "def generate_data(classes, method = 'hard'):\n",
    "    X = np.random.uniform(-1,1,(1000,2))\n",
    "\n",
    "    # random function\n",
    "    if method == 'hard':\n",
    "        Y = np.sin(X)**2 + np.tanh(X)\n",
    "    else:\n",
    "        Y = X\n",
    "    Y = np.sum(Y,1)\n",
    "    K = np.arange(classes)\n",
    "    \n",
    "\n",
    "\n",
    "    boundaries = [np.quantile(Y,i/classes) for i in range(1,classes)]\n",
    "    boundaries = [np.min(Y)] + boundaries + [np.max(Y) + 10-5]\n",
    "    Y_class = []\n",
    "    for y in Y:\n",
    "        for i in range(0,len(boundaries)-1):\n",
    "            if (boundaries[i] <= y) and (y < boundaries[i+1]):\n",
    "                Y_class.append(i)\n",
    "                break\n",
    "    Y = np.array(Y_class)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def generate_categorical_data():\n",
    "    x1 = np.random.randint(0,4,(1,1000))\n",
    "    x2 = np.random.randint(0,2,(1,1000))\n",
    "\n",
    "    X = np.concatenate([x1,x2],0).T\n",
    "\n",
    "    Y = np.prod(X,1)\n",
    "    Y = np.array(Y > 1,int)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "import pandas as pd\n",
    "\n",
    "# contineous case\n",
    "X,Y = generate_data(5,'easy')\n",
    "\n",
    "N,p = X.shape\n",
    "\n",
    "classes = np.unique(Y)\n",
    "K = len(classes)\n",
    "\n",
    "\n",
    "data = {}\n",
    "PCk = {}\n",
    "\n",
    "for p_i in np.arange(p):\n",
    "    data[p_i] = {}\n",
    "    for k in classes:\n",
    "        data[p_i][k] = {'means':None,'var':None}\n",
    "\n",
    "        \n",
    "for k in classes:\n",
    "    idx = np.where(Y == k)\n",
    "    X_temp = X[idx]\n",
    "    n_k,p_k = X_temp.shape\n",
    "    means = X_temp.mean(0)\n",
    "    \n",
    "    for i,m in enumerate(means):\n",
    "        data[i][k]['means'] = means[i]\n",
    "        \n",
    "    var = X_temp.var(0)\n",
    "    \n",
    "    for i,m in enumerate(var):\n",
    "        data[i][k]['var'] = var[i]\n",
    "        \n",
    "    PCk[k] = n_k/N\n",
    "        \n",
    "# prediction\n",
    "\n",
    "result = np.zeros((n,K))\n",
    "for k in classes:\n",
    "    prob = PCk[k]\n",
    "\n",
    "    n,p = X.shape\n",
    "    res = np.zeros((n,p))\n",
    "\n",
    "    for feature in range(p):\n",
    "        res[:,feature] = multivariate_normal.pdf(X[:,feature], data[feature][k]['means'],data[feature][k]['var'])\n",
    "    result[:,k] = np.prod(res,1)\n",
    "    result[:,k]*=prob\n",
    "prediction = np.argmax(result, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.749"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(prediction == Y)/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>, {0: array([0., 0., 0., 0.])})"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = generate_categorical_data()\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "feature = defaultdict(lambda: np.zeros(4))\n",
    "feature[0]\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([275, 253, 130, 110])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.unique(Y)\n",
    "feature = 0\n",
    "\n",
    "\n",
    "idx = Y == classes[0]\n",
    "X_temp = X[idx]\n",
    "\n",
    "\n",
    "counter_per_class = {}\n",
    "\n",
    "for x in classes:\n",
    "    idx = Y == x\n",
    "    X_temp = X[idx]\n",
    "    counter_per_class[x] = {p:Counter(X_temp[:,p]) for p in range(0,2)}\n",
    "\n",
    "counter_per_class[0][0].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(counter_per_class[0][1].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical case\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "X,Y = generate_categorical_data()\n",
    "\n",
    "N,n_features = X.shape\n",
    "classes = np.unique(Y)\n",
    "K = len(classes)\n",
    "\n",
    "df = pd.DataFrame(X, columns = np.arange(n_features))\n",
    "df['target'] = Y\n",
    "\n",
    "tables = {}\n",
    "\n",
    "# we create a counter table for each feature\n",
    "for feature in range(0,n_features):\n",
    "    df_temp = df[[feature,'target']]\n",
    "    unique_features = np.sort(df_temp[feature].unique())\n",
    "\n",
    "    tables[feature] = pd.DataFrame(columns = classes, index = unique_features)\n",
    "    for feat in unique_features:\n",
    "        for k in classes:\n",
    "            tables[feature][k].loc[feat] = df_temp[(df_temp[feature] == feat) & (df_temp['target'] == k)].count().values[0]\n",
    "            \n",
    "# tables is a dictionary\n",
    "\n",
    "#tables[k] are dataframe for each feature of the X matrix\n",
    "# k is the feature name\n",
    "\n",
    "# each dataframe has columns which are the classes and the rows which are the unique categorical entries of the \n",
    "# X column features sapces\n",
    "PCk = {}\n",
    "for k in classes:\n",
    "    nk,pk = df[(df['target'] == k)].shape\n",
    "    PCk[k] = nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so what are the probabilities\n",
    "def P(feature, class_choice, tables):\n",
    "    total = tables[feature][kk].sum()\n",
    "    probs = tables[feature][kk]/total\n",
    "    return probs\n",
    "\n",
    "\n",
    "# probability \n",
    "result = np.zeros((N,K))\n",
    "for k in classes:\n",
    "    res = np.zeros((N,n_features))\n",
    "    for j in range(0,n_features):\n",
    "        res[:,j] = P(j,k,tables).values[X[:,j]]\n",
    "    result[:,k] = PCk[k]*np.prod(res,1)\n",
    "prediction = np.argmax(result, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34547908, 0.65721997],\n",
       "       [0.34547908, 0.34278003],\n",
       "       [0.34547908, 0.65721997],\n",
       "       ...,\n",
       "       [0.17948718, 0.65721997],\n",
       "       [0.34547908, 0.34278003],\n",
       "       [0.17948718, 0.65721997]])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63756911, -0.71879198])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n",
    "\n",
    "\n",
    "tuples = list(zip(*arrays))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bar', 'one'),\n",
       " ('bar', 'two'),\n",
       " ('baz', 'one'),\n",
       " ('baz', 'two'),\n",
       " ('foo', 'one'),\n",
       " ('foo', 'two'),\n",
       " ('qux', 'one'),\n",
       " ('qux', 'two')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('banknotes.txt', header = None)\n",
    "df.columns = ['X_0','X_1','X_2','X_3','Y']\n",
    "X = df[['X_0','X_1','X_2','X_3']].values\n",
    "y = df['Y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Normal:\n",
    "    def __init__(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def prob(self, x):\n",
    "        prefactor = 1/np.sqrt(2*np.pi*self.sigma*self.sigma)\n",
    "        exponent = -(1/(2*self.sigma*self.sigma))*(x - self.mu)*(x-self.mu)\n",
    "        result = prefactor*np.exp(exponent)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X,y):\n",
    "    feature_parameters = {}\n",
    "    classes_indices = {}\n",
    "    pCk = {}\n",
    "    class_set = list(set(y))\n",
    "    for c in class_set:\n",
    "        pCk[c] = (y == c).sum()/len(y)\n",
    "        classes_indices[c] = np.where(y == c)[0]\n",
    "\n",
    "    for c,v in classes_indices.items():\n",
    "        x = X[v]\n",
    "        temp = {}\n",
    "        for i,col in enumerate(['X_0','X_1','X_2','X_3']):\n",
    "            temp[col] = [x[:,i].mean(),x[:,i].std()]\n",
    "            feature_parameters[c] = temp\n",
    "    \n",
    "    return feature_parameters, pCk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class p_x_ck:\n",
    "    def __init__(self, feature_parameter):\n",
    "        self.feature_parameter = feature_parameter\n",
    "        \n",
    "    def _get_probs(self, ck):\n",
    "        parameters = list(feature_parameters[ck].values())\n",
    "        dists = [Normal(p[0],p[1]) for p in parameters]\n",
    "        return dists\n",
    "    \n",
    "    def get(self,datapoint, ck):\n",
    "        res = 1\n",
    "        for pairs in list(zip(self._get_probs(ck),datapoint)):\n",
    "            res*=pairs[0].prob(pairs[1])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.feature_parameters = None\n",
    "        self.pCk = None\n",
    "        self.pck = None\n",
    "    \n",
    "    def train(self, X,y):\n",
    "        self.feature_parameters, self.pCk = get_features(X,y)\n",
    "        self.pck = p_x_ck(self.feature_parameters)\n",
    "        \n",
    "    def predict(self, datapoint, c):\n",
    "        return pck.get(datapoint,c)*pCk[c]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "nb.train(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for x in X:\n",
    "    y_pred.append(np.argmax([nb.predict(x,0),nb.predict(x,1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84110787172011658"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.array(y_pred) == y).sum()/len(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
