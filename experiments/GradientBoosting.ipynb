{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_data(filename):\n",
    "\n",
    "    data = pd.read_csv(filename, sep = '\\t', header = None)\n",
    "\n",
    "    data.columns = ['Frequency','Angle of Attack','Chord length','Free stream velocity','Suction','Pressure']\n",
    "\n",
    "    return data\n",
    "\n",
    "filename = 'airfoil_self_noise.dat'\n",
    "\n",
    "df = get_data(filename)\n",
    "\n",
    "for _ in range(10):\n",
    "    df.sample(frac = 1)\n",
    "\n",
    "Y = df['Pressure']\n",
    "X = df[['Frequency','Angle of Attack', 'Chord length','Free stream velocity','Suction']]\n",
    "\n",
    "split = 0.8\n",
    "split*=len(X)\n",
    "split = int(split)\n",
    "\n",
    "X_train ,X_val = X[:split], X[split:]\n",
    "y_train, y_val = Y[:split], Y[split:]\n",
    "\n",
    "\n",
    "N, p= X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.42246255104156"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what would vanilla linear regression give\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "mean_squared_error(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us try some gradient boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "    def __init__(self, loss_function, dloss_function):\n",
    "        self.loss = loss_function\n",
    "        self.dloss = dloss_function\n",
    "        self.models = []\n",
    "        self.gammas = []\n",
    "        \n",
    "    def setUp(self, X_train, y_train):\n",
    "        self.X = X_train\n",
    "        self.N, self.p = self.X.shape\n",
    "        self.y = y_train\n",
    "        \n",
    "    def _find_gamma(self, gamma, F_init, h_model):\n",
    "        return self.loss(self.y, F_init + gamma*h_model.predict(self.X))\n",
    "                         \n",
    "    def _find_h_model(self, model, F_init):\n",
    "        \"\"\"\n",
    "        Assumes to have a model.fit API call.\n",
    "        \"\"\"\n",
    "        #F_init = np.mean(self.y)\n",
    "        L_diff = -self.dloss(self.y,F_init)\n",
    "        model.fit(X_train, L_diff)\n",
    "        return model\n",
    "    \n",
    "    def _minimise_for_gamma(self, gamma_0, F_init, h_model, opt_verbose = False):\n",
    "        def get_gamma(gamma):\n",
    "            return self._find_gamma(gamma, F_init, h_model)\n",
    "        \n",
    "        res = minimize(get_gamma, gamma_0, method='nelder-mead',\n",
    "                       options={'xatol': 1e-8, 'disp': opt_verbose})\n",
    "\n",
    "        gamma_next = res['x']\n",
    "        return gamma_next\n",
    "        \n",
    "        #F_next = F_init + gamma_next*hm.predict(X_train)\n",
    "        \n",
    "    def _get_F_next(self, model, F_init, gamma_0,opt_verbose = False, print_current_loss = False):\n",
    "        h_model = self._find_h_model(model, F_init)\n",
    "\n",
    "        gamma_next = self._minimise_for_gamma(gamma_0, F_init, h_model, opt_verbose)\n",
    "\n",
    "        F_next = F_init + gamma_next*h_model.predict(self.X)\n",
    "        \n",
    "        if print_current_loss:\n",
    "            print(self.loss(F_next, self.y))\n",
    "        return F_next, gamma_next\n",
    "    \n",
    "    def run_iteration(self, F_init, model, gamma_0, print_every = 50):\n",
    "\n",
    "        gamma_0 = 200\n",
    "        if print_every and print_every%50 == 0:\n",
    "            F_next,gamma_next = gb._get_F_next(model, F_init, gamma_0, False, True)\n",
    "        else:\n",
    "            F_next,gamma_next = gb._get_F_next(model, F_init, gamma_0, False, False)\n",
    "            \n",
    "        self.models.append(model)\n",
    "        self.gammas.append(gamma_next)\n",
    "        F_init = F_next\n",
    "        \n",
    "        \n",
    "        return F_init\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, gamma_0 = 0.5, models = None, max_iteration = 10, print_every = None):\n",
    "        self.setUp(X, y)\n",
    "        F_init = np.mean(self.y)\n",
    "        self.F0 = F_init\n",
    "        if models is None:\n",
    "            for M in range(0,max_iteration):\n",
    "                model = LinearRegression()\n",
    "                F_init = gb.run_iteration(F_init, model, gamma_0, print_every)\n",
    "            \n",
    "            \n",
    "    def predict(self, X):\n",
    "        M = len(self.gammas)\n",
    "        y_pred = np.sum(np.array([self.gammas[i]*self.models[i].predict(X) for i in range(0,M)]),0) + self.F0\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.42246255217496"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss(x,y):\n",
    "    diff = x-y\n",
    "    diff = diff**2\n",
    "    return np.mean(diff)\n",
    "\n",
    "def dloss(x,y):\n",
    "    diff = (y - x)/len(x)\n",
    "    return diff\n",
    "\n",
    "gb = GradientBoosting(loss, dloss)\n",
    "gb.setUp(X_train, y_train)\n",
    "\n",
    "F_init = np.mean(gb.y)\n",
    "model = LinearRegression()\n",
    "gamma_0 = 0.0\n",
    "gb.fit(X_train, y_train)\n",
    "loss(gb.predict(X_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.02107903751532"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tree algorithm?\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "mean_squared_error(model.predict(X_val),y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingTreeRegressor:\n",
    "    def __init__(self, n_estimators, max_depth, max_leaf_nodes, loss_function):\n",
    "        self.n_estimators  = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.loss = loss_function\n",
    "        self.models = []\n",
    "        self.errors = []\n",
    "        self.F0 = None\n",
    "        \n",
    "    def setUp(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def init_model(self):\n",
    "        self.F0 = np.mean(self.y)\n",
    "        return np.array([self.F0]*len(self.y))\n",
    "\n",
    "        \n",
    "    def run_iteration(self, y_init, model):\n",
    "        error = self.y - y_init\n",
    "        model.fit(self.X, error)\n",
    "        y_pred = y_init + model.predict(self.X)\n",
    "        #self.F.append(y_pred)\n",
    "        self.models.append(model)\n",
    "        self.errors.append(error)\n",
    "        return self.loss(y_pred, y_train), y_pred\n",
    "    \n",
    "    def fit(self, X, y, print_every = 10):\n",
    "        self.setUp(X, y)\n",
    "        y_pred = self.init_model()\n",
    "        for _ in range(self.n_estimators):\n",
    "            model = DecisionTreeRegressor(max_depth = self.max_depth, max_leaf_nodes = self.max_leaf_nodes)\n",
    "            loss, y_pred = gbtr.run_iteration(y_pred, model)\n",
    "            #self.F.append(y_pred)\n",
    "            if _%print_every == 0:\n",
    "                print(loss)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        return np.sum(np.array([self.models[i].predict(X) for i in range(0,self.n_estimators)]),0) + self.F0\n",
    "        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.691384372374303\n",
      "0.35596546918175387\n",
      "0.0700148503629082\n",
      "0.014550623232145612\n",
      "0.0034839129483134118\n",
      "0.0007301605760442672\n"
     ]
    }
   ],
   "source": [
    "gbtr = GradientBoostingTreeRegressor(n_estimators = 60, max_depth = 7, max_leaf_nodes = None, \n",
    "                                     loss_function = mean_squared_error)\n",
    "\n",
    "gbtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012652557976002718"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(gbtr.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.571446399343692"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(gbtr.predict(X_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is wrong - need to examine how the to take a derivative of the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124.60557820299503"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbtr.F0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = gbtr.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([126.201     , 125.716415  , 125.716415  , ..., 127.78471469,\n",
       "       132.66143563, 138.11592713])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbtr.F0 + models[0].predict(X_train) + models[1].predict(X_train) + models[2].predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       126.201\n",
       "1       125.201\n",
       "2       125.951\n",
       "3       127.591\n",
       "4       127.461\n",
       "         ...   \n",
       "1197    118.416\n",
       "1198    120.766\n",
       "1199    127.676\n",
       "1200    136.886\n",
       "1201    139.226\n",
       "Name: Pressure, Length: 1202, dtype: float64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.012896016807978\n",
      "2.410318900260539\n",
      "1.6672565083221378\n",
      "1.3159623746623579\n",
      "0.8827646630431142\n",
      "0.7419458340871492\n",
      "0.5612162399182049\n",
      "0.5237981730856289\n",
      "0.4318269937802575\n",
      "0.35596546918175453\n",
      "0.3250971694886142\n",
      "0.28406979104250757\n",
      "0.24295514739453994\n",
      "0.1785937401588718\n",
      "0.14788741568926456\n",
      "0.12250339934003468\n",
      "0.10697934346109872\n",
      "0.09299953627204012\n",
      "0.08048857714589873\n",
      "0.0700148503629082\n",
      "0.05728736295562408\n",
      "0.04404291441367991\n",
      "0.03885994245139565\n",
      "0.031405173572276485\n",
      "0.029385697833963425\n",
      "0.02704171537041256\n",
      "0.0194956577589255\n",
      "0.01802475673922405\n",
      "0.016293872094202633\n",
      "0.014550623232145662\n"
     ]
    }
   ],
   "source": [
    "gbtr = GradientBoostingTreeRegressor(n_estimators = 100, max_depth = 7, max_leaf_nodes = None, \n",
    "                                     loss_function = mean_squared_error)\n",
    "\n",
    "gbtr.setUp(X_train, y_train)\n",
    "model, y_pred = gbtr.init_model()\n",
    "\n",
    "for _ in range(0,30):\n",
    "    model = DecisionTreeRegressor( max_depth = 7)\n",
    "    loss, y_pred = gbtr.run_iteration(y_pred, model)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.492315679317933"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how this compares with XGBoost.\n",
    "\n",
    "import xgboost\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)\n",
    "\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_val)\n",
    "\n",
    "loss(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('ml_env': conda)",
   "language": "python",
   "name": "python36964bitmlenvconda9f54039d931e4029adcffd4ea832f0f0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
