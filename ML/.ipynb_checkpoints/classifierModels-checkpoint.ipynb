{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import autograd.numpy as np\n",
    "import scipy.linalg as la \n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "\n",
    "from abc import ABCMeta\n",
    "from abc import abstractmethod\n",
    "\n",
    "class ClassifierModel:\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    def __init__(self, method = None):\n",
    "        self.X = 0\n",
    "        self.y = 0\n",
    "        self.n, self.p = None, None\n",
    "        self.weights = None\n",
    "        self.sample = None\n",
    "        self.method = method\n",
    "        \n",
    "    def setUp(self,X,y):\n",
    "        \n",
    "        X_train = X.copy()\n",
    "        y_train = y.copy()\n",
    "        \n",
    "        self.k = len(np.unique(y_train))\n",
    "        self.X = X_train\n",
    "        self.y = y_train\n",
    "\n",
    "        self.X = np.insert(self.X, 0, values=1, axis=1)\n",
    "        \n",
    "        self.n,self.p = self.X.shape\n",
    "       \n",
    "    @abstractmethod\n",
    "    def weights_init(self):\n",
    "        return\n",
    "        \n",
    "    @abstractmethod\n",
    "    def loss(self):\n",
    "        return\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y):\n",
    "        return\n",
    "\n",
    "\n",
    "class LogisticRegression(ClassifierModel):\n",
    "    \"\"\"\n",
    "    data needs to be centered.\n",
    "    \"\"\"\n",
    "    def __init__(self,lagriangian_constant, method):\n",
    "        ClassifierModel.__init__(self, method)\n",
    "        self.lagriangian_constant = lagriangian_constant\n",
    "        self.method = method\n",
    "        self.binary = False\n",
    "\n",
    "    def weights_init(self, X):\n",
    "        self.weights = X.mean(0) + np.random.random()\n",
    "        \n",
    "    def weights_multi_init(self, X):\n",
    "        self.weights = np.random.multivariate_normal(X.mean(0),np.eye(len(X.mean(0))),(self.k))\n",
    "    \n",
    "    def _sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def _softmax(self, array):\n",
    "        num = np.exp(array)\n",
    "        den = sum(num)\n",
    "        return num/den\n",
    "    \n",
    "    def _create_one_hot(self, Y, num_categories):\n",
    "        Y = Y.reshape(1,len(Y)).ravel()\n",
    "\n",
    "        def create_arr(number, num_cat):\n",
    "            res = np.zeros(num_categories)\n",
    "            res[number] = 1\n",
    "            return res\n",
    "\n",
    "        return np.array(list(map(lambda x: create_arr(x, num_categories), Y)))\n",
    "    \n",
    "    def loss_binary(self, weights):\n",
    "        probabilities = self._sigmoid(np.matmul(self.X, weights)).reshape(-1,1)\n",
    "\n",
    "        loss_i = np.multiply(self.y,np.log(probabilities)) + np.multiply((1-self.y),np.log(1-probabilities))\n",
    "        loss = -np.mean(loss_i)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    \n",
    "    def loss_multiple(self, weights):\n",
    "        #print(weights.shape)\n",
    "        #print(self.X.shape)\n",
    "        log_softmax = np.log(np.array(list(map(lambda x: self._softmax(x),np.matmul(self.X, weights.T)))))\n",
    "        ys_one_hot = create_one_hot(self.y,self.k)\n",
    "        loss = -np.mean(np.multiply(ys_one_hot, log_softmax))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.setUp(X,y)\n",
    "        \n",
    "        if len(np.unique(self.y)) == 2:\n",
    "            self.binary = True\n",
    "            self.weights_init(self.X)\n",
    "            self.method._weights_init(self.weights)\n",
    "            self.method._loss_function(self.loss_binary)\n",
    "            self.method.optimise()\n",
    "            self.weights = self.method.get_weights()\n",
    "        else:\n",
    "            self.weights_multi_init(self.X)\n",
    "            self.method._weights_init(self.weights)\n",
    "            self.method._loss_function(self.loss_multiple)\n",
    "            self.method.optimise()\n",
    "            self.weights = self.method.get_weights()\n",
    "            \n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        if self.binary:\n",
    "            probabilities = self._sigmoid(np.matmul(self.X, self.weights)).reshape(-1,1)\n",
    "            return probabilities\n",
    "        else:\n",
    "            probabilities = np.array(list(map(lambda x: lr._softmax(x),np.matmul(lr.X, lr.weights.T))))\n",
    "            return probabilities\n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.binary:\n",
    "            probs = self.predict_proba(X)\n",
    "            return np.array(lr.predict_proba(X)>0.5,int)\n",
    "        else:\n",
    "            probs = self.predict_proba(X)\n",
    "            return np.argmax(lr.predict_proba(X),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28082df45034cf78aae5bda97054324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# multinomial case\n",
    "\n",
    "X = np.random.normal(0,1,(100,2))\n",
    "Y = []\n",
    "data = X.sum(1)\n",
    "for v in data:\n",
    "    if v < -0.3:\n",
    "        Y.append(0)\n",
    "    elif v >= -0.3 and v < 0.3:\n",
    "        Y.append(1)\n",
    "    else:\n",
    "        Y.append(2)\n",
    "Y = np.array(Y).reshape(-1,1)\n",
    "X = np.insert(X, 0, values=1, axis=1)\n",
    "\n",
    "optimiser = gd(0.1,max_iteration = 1000,tolerance = 0.0,notebook = True)\n",
    "lr = LogisticRegression(lagriangian_constant=0.001,method = optimiser)\n",
    "lr.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(lr.predict(X).reshape(-1,1) == Y,int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83227e197daf4acba20f31913631155f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from optimiser import gradientDescent as gd\n",
    "\n",
    "X = np.random.normal(0,1,(100,2))\n",
    "Y = np.array(X.sum(1) > 0,int).reshape(-1,1)\n",
    "X = np.insert(X, 0, values=1, axis=1)\n",
    "\n",
    "optimiser = gd(0.01,max_iteration = 5000,tolerance = 0.0,notebook = True)\n",
    "lr = LogisticRegression(lagriangian_constant=0.001,method = optimiser)\n",
    "lr.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(lr.predict(X) == Y,int).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('ml_env': conda)",
   "language": "python",
   "name": "python36964bitmlenvconda9f54039d931e4029adcffd4ea832f0f0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
